# Azure Subscription Variables
TENANT_ID = '461e2020-109b-4c43-ad3f-eb9944f5dc44'
SUBSCRIPTION_ID = 'bf088f59-f015-4332-bd36-54b988be7c90'
LOCATION = 'westeurope'
BASE_NAME = 'sb94'
SP_APP_ID = '8a0b5ebf-55c7-4dfa-a49c-37b0acd9c3ce'
SP_APP_SECRET = '5tG.N6t9_wKmzV4.gP3pOTYwwXF2i-1jDR'
RESOURCE_GROUP = 'amlbrikserg'

# Mock build/release ID for local testing
BUILD_BUILDID = '001'

# Azure ML Workspace Variables
WORKSPACE_NAME = 'amlbriksews'
EXPERIMENT_NAME = 'fowl-pytorch'

# AML Compute Cluster Config
AML_ENV_NAME='pytorch-aml-env'
AML_ENV_TRAIN_CONDA_DEP_FILE='environment.yml'
AML_COMPUTE_CLUSTER_NAME = 'train-cluster'
AML_COMPUTE_CLUSTER_CPU_SKU = 'STANDARD_DS2_V2'
AML_CLUSTER_MAX_NODES = '4'
AML_CLUSTER_MIN_NODES = '0'
AML_CLUSTER_PRIORITY = 'lowpriority'

# Training Config
MODEL_NAME = 'fowl_model.pt'
MODEL_VERSION = '1'
TRAIN_SCRIPT_PATH = 'training/train.py'

# AML Pipeline Config
TRAINING_PIPELINE_NAME = 'Training Pipeline'
MODEL_PATH = ''
EVALUATE_SCRIPT_PATH = 'evaluate/evaluate_model.py'
REGISTER_SCRIPT_PATH = 'register/register_model.py'
SOURCES_DIR_TRAIN = 'src/training'
DATASET_NAME = 'fowl-dataset'
DATASET_VERSION = '1'
# Optional. Set it if you have configured non default datastore to point to your data
DATASTORE_NAME = ''
SCORE_SCRIPT = 'scoring/score.py'
CONDA_ENV_DIR='environments/conda'

# Optional. Used by a training pipeline with R on Databricks
DB_CLUSTER_ID = ''

# Optional. Container Image name for image creation
IMAGE_NAME = 'mltrained'

# Run Evaluation Step in AML pipeline
RUN_EVALUATION = 'true'

# Set to true cancels the Azure ML pipeline run when evaluation criteria are not met.
ALLOW_RUN_CANCEL = 'true'

# Flag to allow rebuilding the AML Environment after it was built for the first time. This enables dependency updates from conda_dependencies.yaml.
AML_REBUILD_ENVIRONMENT = 'false'



USE_GPU_FOR_SCORING = "false"
AML_ENV_SCORE_CONDA_DEP_FILE="conda_dependencies_scoring.yml"
AML_ENV_SCORECOPY_CONDA_DEP_FILE="conda_dependencies_scorecopy.yml"
# AML Compute Cluster Config for parallel batch scoring
AML_ENV_NAME_SCORING='diabetes_regression_scoring_env'
AML_ENV_NAME_SCORE_COPY='diabetes_regression_score_copy_env'
AML_COMPUTE_CLUSTER_NAME_SCORING = 'score-cluster'
AML_COMPUTE_CLUSTER_CPU_SKU_SCORING = 'STANDARD_DS2_V2'
AML_CLUSTER_MAX_NODES_SCORING = '4'
AML_CLUSTER_MIN_NODES_SCORING = '0'
AML_CLUSTER_PRIORITY_SCORING = 'lowpriority'
AML_REBUILD_ENVIRONMENT_SCORING = 'true'
BATCHSCORE_SCRIPT_PATH = 'scoring/parallel_batchscore.py'
BATCHSCORE_COPY_SCRIPT_PATH = 'scoring/parallel_batchscore_copyoutput.py'


SCORING_DATASTORE_INPUT_CONTAINER = 'input'
SCORING_DATASTORE_INPUT_FILENAME = 'diabetes_scoring_input.csv'
SCORING_DATASTORE_OUTPUT_CONTAINER = 'output'
SCORING_DATASTORE_OUTPUT_FILENAME = 'diabetes_scoring_output.csv'
SCORING_DATASET_NAME = 'diabetes_scoring_ds'
SCORING_PIPELINE_NAME = 'diabetes-scoring-pipeline'

# To be removed!
AML_SERVICE_PRINCIPAL_PASSWORD=~IwB8ryrB.F1RF82Zxh96WYc~7.jgvX2V7